step1Request:
  generationConfig:
    maxOutputTokens: 4096
    temperature: 0.5
    topP: 0.95
    responseMimeType: application/json
    responseSchema:
      type: object
      properties:
        say:
          type: string
          pattern: (?=IMPOSSIBLE)hello
          description: A single word to say
      required:
        - say
  contents:
    - role: user
      parts:
        - text: Say hello!
step2RawChunks:
  - candidates:
      - content:
          role: model
          parts:
            - text: '{"'
        index: 0
    usageMetadata:
      trafficType: ON_DEMAND
  - candidates:
      - content:
          role: model
          parts:
            - text: 'say": "Hello"}'
        finishReason: STOP
        index: 0
    usageMetadata:
      promptTokenCount: 16
      candidatesTokenCount: 6
      totalTokenCount: 22
      trafficType: ON_DEMAND
      promptTokensDetails:
        - modality: TEXT
          tokenCount: 16
      candidatesTokensDetails:
        - modality: TEXT
          tokenCount: 6
step3KurtEvents:
  - chunk: '{"'
  - chunk: 'say": "Hello"}'
  - chunk: '{"say": "Hello"}'
