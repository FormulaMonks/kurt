step1Request:
  generationConfig:
    maxOutputTokens: 4096
    temperature: 0.5
    topP: 0.95
    responseMimeType: application/json
    responseSchema:
      type: object
      properties:
        say:
          type: string
          description: A single word to say
      required:
        - say
  contents:
    - role: user
      parts:
        - text: Say hello!
step2RawChunks:
  - candidates:
      - content:
          role: model
          parts:
            - text: '{"'
        index: 0
    usageMetadata:
      trafficType: ON_DEMAND
  - candidates:
      - content:
          role: model
          parts:
            - text: 'say": "Hello!"}'
        finishReason: STOP
        index: 0
    usageMetadata:
      promptTokenCount: 10
      candidatesTokenCount: 7
      totalTokenCount: 17
      trafficType: ON_DEMAND
      promptTokensDetails:
        - modality: TEXT
          tokenCount: 10
      candidatesTokensDetails:
        - modality: TEXT
          tokenCount: 7
step3KurtEvents:
  - chunk: '{"'
  - chunk: 'say": "Hello!"}'
  - chunk: '{"say": "Hello!"}'
  - finished: true
    text: '{"say": "Hello!"}'
    data:
      say: Hello!
    metadata:
      totalInputTokens: 10
      totalOutputTokens: 7
